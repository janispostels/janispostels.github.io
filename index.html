<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Janis Postels</title>
  
  <meta name="author" content="Janis Postels">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Janis Postels</name>
              </p>
              <p>I am a PhD candidate at the Computer Vision Lab at ETH Zurich under the supervision of <a href="https://scholar.google.com/citations?user=TwMib_QAAAAJ">Luc Van Gool</a> (ETH Zurich) and <a href="https://scholar.google.com/citations?user=TFsE4BIAAAAJ">Federico Tombari</a> (Google).
              </p>
              <p>
                My research primarliy focuses on uncertainty quantification in deep neural networks. Moreover, I have also worked on neural compression algorithms and generative models for various data modalities.
              </p>
              <p style="text-align:center">
                <a href="mailto:jpostels@ethz.ch">Email</a> &nbsp/&nbsp
                <a href="data/janis_postels_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=_z8NnVsAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/janispostels">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/janisgp">Github</a> &nbsp/&nbsp
                <a href="https://ch.linkedin.com/in/jgpostels">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/janispostels.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/janispostels.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:100%;max-width:100%" alt="teaser image" src="images/inr_compression.png" class="hoverZoomLink">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>Implicit Neural Representations for Image Compression</papertitle>
              </strong>
              <br>
              Yannick Struempler,
              <strong>Janis Postels</strong>,
              Ren Yang,
              Luc Van Gool,
              Federico Tombari
              <br>
							<em>arXiv</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2112.04267">paper</a>
              <p></p>
              <p>We propose a neural image compression algorithm by leveraging neural implicit representations and meta-learning.</p>
            </td>
          </tr>

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:100%;max-width:100%" alt="teaser image" src="images/go_with_the_flows.png" class="hoverZoomLink">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>Go with the Flows: Mixtures of Normalizing Flows for Point Cloud Generation and Reconstruction</papertitle>
              </strong>
              <br>
              <strong>Janis Postels</strong>,
              Mengya Liu,
              Riccardo Spezialetti,
              Luc Van Gool,
              Federico Tombari
              <br>
							<em>International Conference on 3D Vision</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2106.03135">paper</a> <br>
              <a href="https://github.com/janisgp/go_with_the_flows">code</a>
              <p></p>
              <p>We mitigate drawbacks of prior generative models based on normalizing flows for point clouds by introducing a mixture of normalizing flows.</p>
            </td>
          </tr>

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:100%;max-width:100%" alt="teaser image" src="images/ood_blind_spot.png" class="hoverZoomLink">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>The OOD Blind Spot of Unsupervised Anomaly Detection</papertitle>
              </strong>
              <br>
              Matthäus Heer,
              <strong>Janis Postels</strong>,
              Xiaoran Chen,
              Ender Konukoglu,
              Shadi Albarqouni
              <br>
							<em>Medical Imaging with Deep Learning</em>, 2021
              <br>
              <a href="https://openreview.net/forum?id=ZDD2TbZn7X1">paper</a>
              <p></p>
              <p>We demonstrate the vulnerability of recent approaches based on VAEs for unsupervised anomaly detection in medical images.</p>
            </td>
          </tr>

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle">

            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>On the Practicality of Deterministic Epistemic Uncertainty</papertitle>
              </strong>
              <br>
              <strong>Janis Postels</strong>,
              Mattia Segu,
              Tao Sun,
              Luc Van Gool,
              Fisher Yu,
              Federico Tombari
              <br>
							<em>arXiv</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2107.00649">paper</a>
              <p></p>
              <p>We show that the uncertainty predicted by a recent family of methods for uncertainty estimation which treat the weights of a neural network deterministically is poorly calibrated.</p>
            </td>
          </tr>

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:100%;max-width:100%" alt="teaser image" src="images/vtn.png" class="hoverZoomLink">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>Variational Transformer Networks for Layout Generation</papertitle>
              </strong>
              <br>
              Diego Martin Arroyo,
              <strong>Janis Postels</strong>,
              Federico Tombari
              <br>
							<em>Conference on Computer Vision and Pattern Recognition</em>, 2021
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Arroyo_Variational_Transformer_Networks_for_Layout_Generation_CVPR_2021_paper.html">paper</a>
              <p></p>
              <p>We introduce a generative model for layouts based on VAEs and attention layers and demonstrate its strong inductive bias.</p>
            </td>
          </tr>

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle">

            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>The Hidden Uncertainty in a Neural Networks Activations</papertitle>
              </strong>
              <br>
              <strong>Janis Postels</strong>,
              Hermann Blum,
              Yannick Strümpler,
              Cesar Cadena,
              Roland Siegwart,
              Luc Van Gool,
              Federico Tombari
              <br>
							<em>arXiv</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2012.03082">paper</a>
              <p></p>
              <p>We demonstrate that the uncertainty of a neural network can be quantified using the distribution of its hidden representations.</p>
            </td>
          </tr>

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:100%;max-width:100%" alt="teaser image" src="images/sampling_free_epistemic_uncertainty.png" class="hoverZoomLink">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>
                <papertitle>Sampling-free epistemic uncertainty estimation using approximated variance propagation</papertitle>
              </strong>
              <br>
              <strong>Janis Postels</strong>,
              Francesco Ferroni,
              Huseyin Coskun,
              Nassir Navab,
              Federico Tombari
              <br>
							<em>International Conference on Computer Vision (ORAL)</em>, 2019
              <br>
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Postels_Sampling-Free_Epistemic_Uncertainty_Estimation_Using_Approximated_Variance_Propagation_ICCV_2019_paper.html">paper</a>
              <a href="https://github.com/janisgp/Sampling-free-Epistemic-Uncertainty">code</a>
              <p></p>
              <p>We propose a method to estimate the uncertainty of Bayesian neural networks in a single forward pass by applying error propagation.</p>
            </td>
          </tr>


        </tbody></table>

        <a href="https://github.com/jonbarron/website">Link to Template</a>

      </td>
    </tr>
  </table>
</body>

</html>
